{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML4NLP1\n",
        "## Starting Point for Exercise 1, part II\n",
        "\n",
        "This notebook is supposed to serve as a starting point and/or inspiration when starting exercise 1, part II.\n",
        "\n",
        "One of the goals of this exercise is o make you acquainted with **skorch**. You will probably need to consult the [documentation](https://skorch.readthedocs.io/en/stable/)."
      ],
      "metadata": {
        "id": "Q-2GcUhgB0S7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V920LTuiq40d"
      },
      "source": [
        "# Installing skorch and loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utYcb97jq40t"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "# Installation on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch'])\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ3Y_KHvq40x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from skorch import NeuralNetClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9d6X0ZZq40z"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H55IvQdyq403"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import string\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnY8yaDq400"
      },
      "source": [
        "## Training a classifier and making predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "!gdown 1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs # x_train\n",
        "!gdown 1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6 # x_test\n",
        "!gdown 1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl # y_train\n",
        "!gdown 1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X # y_test"
      ],
      "metadata": {
        "id": "zWjt9xGoswAC",
        "outputId": "8e0981ff-995f-482f-ab47-eb25c2601719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs\n",
            "To: /content/x_train.txt\n",
            "100% 64.1M/64.1M [00:00<00:00, 190MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6\n",
            "To: /content/x_test.txt\n",
            "100% 65.2M/65.2M [00:00<00:00, 154MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl\n",
            "To: /content/y_train.txt\n",
            "100% 480k/480k [00:00<00:00, 107MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X\n",
            "To: /content/y_test.txt\n",
            "100% 480k/480k [00:00<00:00, 23.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'x_train.txt') as f:\n",
        "    x_train = f.read().splitlines()\n",
        "with open(f'y_train.txt') as f:\n",
        "    y_train = f.read().splitlines()\n",
        "with open(f'x_test.txt') as f:\n",
        "    x_test = f.read().splitlines()\n",
        "with open(f'y_test.txt') as f:\n",
        "    y_test = f.read().splitlines()"
      ],
      "metadata": {
        "id": "-M6DgXdjtJyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# combine x_train and y_train into one dataframe\n",
        "train_df = pd.DataFrame({'text': x_train, 'label': y_train})\n",
        "\n",
        "#combine x_test and y_test into one dataframe\n",
        "test_df = pd.DataFrame({'text': x_test, 'label': y_test})"
      ],
      "metadata": {
        "id": "oRqfDA9FuoX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T: Please use again the train/test data that includes English, German, Dutch, Danish, Swedish and Norwegian, plus 20 additional languages of your choice (the labels can be found in the file labels.csv)\n",
        "# and adjust the train/test split if needed\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Combine train and test for initial merge\n",
        "combined_df = pd.concat([train_df, test_df])\n",
        "\n",
        "# Split combined_df into 80% training and 20% testing while stratifying by label\n",
        "train_df, test_df = train_test_split(combined_df, test_size=0.2, random_state=42, stratify=combined_df['label'])\n",
        "\n",
        "selected_labels = ['eng', 'deu', 'nld', 'dan', 'swe', 'nno', 'ace', 'afr', 'als', 'amh', 'ang', 'ara', 'arg', 'arz', 'asm',\n",
        "                   'ast', 'ava', 'aym', 'azb', 'aze', 'bak', 'bar', 'bcl', 'kom', 'bel', 'jpn']\n",
        "\n",
        "train_subset = train_df[train_df['label'].isin(selected_labels)]\n",
        "test_subset = test_df[test_df['label'].isin(selected_labels)]\n",
        "\n",
        "# Define X_train, y_train, X_test, y_test\n",
        "X_train = train_subset['text']\n",
        "y_train = train_subset['label']\n",
        "X_test = test_subset['text']\n",
        "y_test = test_subset['label']"
      ],
      "metadata": {
        "id": "r2cICoZ8xNMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T: use your adjusted code to encode the labels here\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Preprocessing\n",
        "label_encoder = LabelEncoder()\n",
        "le_fitted = label_encoder.fit(y_train)\n",
        "\n",
        "y_train = le_fitted.transform(y_train)\n",
        "y_test = le_fitted.transform(y_test)"
      ],
      "metadata": {
        "id": "PXpIOpjRxzTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(le_fitted.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLzTdsBLaKip",
        "outputId": "c2de8a15-1405-40e5-e116-bdf76d670fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T: In the following, you can find a small (almost) working example of a neural network. Unfortunately, again, the cat messed up some of the code. Please fix the code such that it is executable."
      ],
      "metadata": {
        "id": "212FI4CFFnrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we extract some simple features as input for the neural network\n",
        "# vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=100, binary=True)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1), binary=False)\n",
        "X = vectorizer.fit_transform(X_train.to_numpy())"
      ],
      "metadata": {
        "id": "2-Ls0e0GQgMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.astype(np.float32)\n",
        "# y = y_train_dev.astype(np.int64)\n",
        "y = y_train.astype(np.int64)\n",
        "\n",
        "X.shape"
      ],
      "metadata": {
        "id": "9EiRal_1Q0iJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76ba005-b2c6-43fa-faf0-095104769b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800, 3773)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMFoiitJq407"
      },
      "source": [
        "In the following, we define a vanilla neural network with two hidden layers. The output layer should have as many outputs as there are classes. In addition, it should have a nonlinearity function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=200,\n",
        "            nonlin=F.relu,\n",
        "    ):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        self.dense0 = nn.Linear(3773, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, 26)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "      X = self.nonlin(self.dense0(X))\n",
        "      X = F.relu(self.dense1(X))\n",
        "      X = self.output(X)\n",
        "      return X.squeeze(dim=1)"
      ],
      "metadata": {
        "id": "7Q5EDIGQUUBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.1,\n",
        "    device='cuda',  # comment this to train with CPU\n",
        ")"
      ],
      "metadata": {
        "id": "wKnJECeQGpyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fit(X, y)"
      ],
      "metadata": {
        "id": "QcNOd9yBSxys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d5fe0e-d2c2-43e3-eda9-a205cc602654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.9458\u001b[0m       \u001b[32m0.5474\u001b[0m        \u001b[35m1.4507\u001b[0m  2.6593\n",
            "      2        \u001b[36m1.2858\u001b[0m       \u001b[32m0.5767\u001b[0m        1.7106  2.2737\n",
            "      3        \u001b[36m1.2798\u001b[0m       0.5361        1.6135  3.0214\n",
            "      4        \u001b[36m0.8908\u001b[0m       \u001b[32m0.7755\u001b[0m        \u001b[35m0.7108\u001b[0m  2.1752\n",
            "      5        \u001b[36m0.8529\u001b[0m       0.6851        0.9602  2.2089\n",
            "      6        1.0722       0.6288        1.1909  2.2045\n",
            "      7        1.2545       0.6325        1.0642  2.1938\n",
            "      8        0.9495       \u001b[32m0.8202\u001b[0m        \u001b[35m0.6266\u001b[0m  3.1278\n",
            "      9        \u001b[36m0.7006\u001b[0m       0.8034        0.6292  2.2572\n",
            "     10        \u001b[36m0.5889\u001b[0m       0.8175        \u001b[35m0.5894\u001b[0m  2.2957\n",
            "     11        \u001b[36m0.5795\u001b[0m       \u001b[32m0.8365\u001b[0m        \u001b[35m0.5370\u001b[0m  2.2505\n",
            "     12        0.7443       \u001b[32m0.8495\u001b[0m        \u001b[35m0.5285\u001b[0m  2.2892\n",
            "     13        \u001b[36m0.5337\u001b[0m       \u001b[32m0.8654\u001b[0m        \u001b[35m0.4452\u001b[0m  3.1296\n",
            "     14        0.5972       0.8380        0.5055  2.2192\n",
            "     15        1.7057       0.6685        1.0492  2.2666\n",
            "     16        1.1500       0.6502        1.0326  2.3407\n",
            "     17        1.1222       0.6440        1.1223  2.3120\n",
            "     18        0.9786       0.7423        0.8242  2.9835\n",
            "     19        0.8318       0.7317        0.7570  2.3510\n",
            "     20        1.7621       0.5471        1.4527  2.2814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule(\n",
              "    (dense0): Linear(in_features=3773, out_features=200, bias=True)\n",
              "    (dense1): Linear(in_features=200, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=26, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = net.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I49ECwaUGS3v",
        "outputId": "28d58383-787f-49b0-cabe-08f5ca1a3742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5506730769230769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch.callbacks import EarlyStopping\n",
        "\n",
        "class Module1(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=2500,\n",
        "            nonlin=F.relu,\n",
        "    ):\n",
        "        super(Module1, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        self.dense0 = nn.Linear(3773, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 256)\n",
        "        self.output = nn.Linear(256, 26)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "      X = self.nonlin(self.dense0(X))\n",
        "      X = F.tanh(self.dense1(X))\n",
        "      X = self.output(X)\n",
        "      return X.squeeze(dim=1)\n",
        "\n",
        "# Add early stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='valid_loss',\n",
        "    patience=10,\n",
        "    threshold=0.0001,  # Minimum threshold for loss improvement\n",
        "    threshold_mode='rel',\n",
        "    lower_is_better=True\n",
        ")\n",
        "\n",
        "net1 = NeuralNetClassifier(\n",
        "    Module1,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.001,\n",
        "    optimizer=torch.optim.RMSprop,\n",
        "    device='cuda',\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "net1.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV0EwqW4HGmb",
        "outputId": "addd3c22-26ff-4ee1-f3d4-09a11ba0c8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5324\u001b[0m       \u001b[32m0.8115\u001b[0m        \u001b[35m0.5470\u001b[0m  2.8338\n",
            "      2        \u001b[36m0.3680\u001b[0m       \u001b[32m0.9161\u001b[0m        \u001b[35m0.2823\u001b[0m  3.5324\n",
            "      3        \u001b[36m0.2529\u001b[0m       0.9161        \u001b[35m0.2645\u001b[0m  3.4568\n",
            "      4        \u001b[36m0.2169\u001b[0m       0.9156        0.2722  6.2322\n",
            "      5        \u001b[36m0.1913\u001b[0m       \u001b[32m0.9209\u001b[0m        \u001b[35m0.2574\u001b[0m  3.5753\n",
            "      6        \u001b[36m0.1702\u001b[0m       \u001b[32m0.9219\u001b[0m        0.2671  2.7637\n",
            "      7        \u001b[36m0.1540\u001b[0m       0.9202        0.2621  2.6958\n",
            "      8        \u001b[36m0.1386\u001b[0m       \u001b[32m0.9281\u001b[0m        \u001b[35m0.2509\u001b[0m  2.7752\n",
            "      9        \u001b[36m0.1288\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m0.2400\u001b[0m  3.4730\n",
            "     10        \u001b[36m0.1146\u001b[0m       \u001b[32m0.9327\u001b[0m        0.2434  2.8422\n",
            "     11        \u001b[36m0.1048\u001b[0m       0.9269        0.2553  2.8619\n",
            "     12        \u001b[36m0.0896\u001b[0m       \u001b[32m0.9334\u001b[0m        0.2571  2.7953\n",
            "     13        \u001b[36m0.0864\u001b[0m       \u001b[32m0.9356\u001b[0m        0.2459  3.4442\n",
            "     14        \u001b[36m0.0855\u001b[0m       0.9339        0.2506  2.9214\n",
            "     15        \u001b[36m0.0737\u001b[0m       0.9341        0.2507  2.8102\n",
            "     16        \u001b[36m0.0692\u001b[0m       0.9272        0.2795  2.7475\n",
            "     17        \u001b[36m0.0615\u001b[0m       \u001b[32m0.9358\u001b[0m        0.2665  3.3724\n",
            "     18        \u001b[36m0.0569\u001b[0m       0.9315        0.2909  2.9610\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=Module1(\n",
              "    (dense0): Linear(in_features=3773, out_features=2500, bias=True)\n",
              "    (dense1): Linear(in_features=2500, out_features=256, bias=True)\n",
              "    (output): Linear(in_features=256, out_features=26, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_1 = net1.predict(X)\n",
        "accuracy_1 = accuracy_score(y, y_pred_1)\n",
        "\n",
        "print(f'Accuracy1: {accuracy_1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I1kbq05JhgG",
        "outputId": "b9a6bdbe-2f9a-4761-ddc6-3d16a1b10f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy1: 0.9711057692307692\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd97b8bffa4d3737e84826bc3d37be3046061822757ce35137ab82ad4c5a2016"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}